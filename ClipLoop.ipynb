{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheOneTrueGuy/DigitalDayDream/blob/main/ClipLoop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o88Utuba8NiT"
      },
      "source": [
        "Digital daydreaming in latent space with CLIP Interogator and Stable Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INL8Ds7z8dO5"
      },
      "outputs": [],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnIEAOOrEPIP"
      },
      "outputs": [],
      "source": [
        "#@title Installation\n",
        "!sudo apt update\n",
        "import os, subprocess, sys\n",
        "\n",
        "def setup():\n",
        "    install_cmds = [\n",
        "        ['pip', 'install', 'diffusers==0.10.0'],\n",
        "        ['pip', 'install', 'gradio', ],\n",
        "        ['pip', 'install', '-e', 'git+https://github.com/MirageML/BLIP.git@main#egg=blip'],#  https://github.com/pharmapsychotic/BLIP.git@lib#egg=blip'],\n",
        "        ['pip', 'install', 'clip-interrogator==0.3.1' ]\n",
        "    ]\n",
        "    for cmd in install_cmds:\n",
        "        print(subprocess.run(cmd, stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "\n",
        "setup()\n",
        "\n",
        "\n",
        "\n",
        "# save time of preprocessing by downloading cache from huggingface\n",
        "print(\"Download preprocessed cache files...\")\n",
        "CACHE_URLS = [\n",
        "    'https://huggingface.co/pharma/ci-preprocess/resolve/main/ViT-L-14_openai_artists.pkl',\n",
        "    'https://huggingface.co/pharma/ci-preprocess/resolve/main/ViT-L-14_openai_flavors.pkl',\n",
        "    'https://huggingface.co/pharma/ci-preprocess/resolve/main/ViT-L-14_openai_mediums.pkl',\n",
        "    'https://huggingface.co/pharma/ci-preprocess/resolve/main/ViT-L-14_openai_movements.pkl',\n",
        "    'https://huggingface.co/pharma/ci-preprocess/resolve/main/ViT-L-14_openai_trendings.pkl',\n",
        "]\n",
        "os.makedirs('cache', exist_ok=True)\n",
        "for url in CACHE_URLS:\n",
        "    print(subprocess.run(['wget', url, '-P', 'cache'], stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "\n",
        "sys.path.append('src/blip')\n",
        "\n",
        "!pip install --upgrade diffusers transformers accelerate\n",
        "\n",
        "from clip_interrogator import Config, Interrogator\n",
        "\n",
        "ci = Interrogator(Config())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arj7-WnR_vCS"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "results_dir = '/content/drive/MyDrive/clip-loop'\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# fetch image_to_image.py\n",
        "!git clone https://github.com/TheOneTrueGuy/DigitalDayDream.git\n",
        "!cp DigitalDayDream/image_to_image.py /content/\n",
        "!cp DigitalDayDream/noiser.py /content/\n",
        "!cp DigitalDayDream/replace.txt /content/\n",
        "\n",
        "print(f\"\\nResults will be saved to {results_dir}\")\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ3Jes5hFsrn"
      },
      "outputs": [],
      "source": [
        "#@title Login to huggingface\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vin6RgA85gT",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#@title Create animation!\n",
        "\n",
        "start_image_path = \"/content/st-0005.png\" #@param {type:\"string\"}\n",
        "style_prompt = \"stylish style from Styleland\" #@param {type:\"string\"}\n",
        "dir_name = \"output_dir\" #@param {type:\"string\"}\n",
        "max_frames = 200 #@param {type:\"integer\"}\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "class FakeSafety():\n",
        "    def __call__(self, clip_input, images):\n",
        "        return (images, False)\n",
        "\n",
        "\n",
        "rond=np.random.randint(7,100000000)\n",
        "generator = torch.Generator(\"cuda\").manual_seed(rond)\n",
        "print( \"random seed \" + str(rond))\n",
        "\n",
        "device = \"cuda\"\n",
        "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)\n",
        "pipe.safety_checker = FakeSafety() #remove/comment out this line to restore adult content filtering\n",
        "\n",
        "os.makedirs(dir_name, exist_ok=True)\n",
        "dialog = open(\"dialog.txt\", \"a\", encoding=\"utf-8\")\n",
        "dialog.write(\"random seed:\"+str(rond) + \"\\n\")\n",
        "for xn in range(0, max_frames, 1):\n",
        "  im = Image.open(start_image_path if xn == 0 else \"prev.png\").convert(\"RGB\")\n",
        "  im = im.resize((512,512))\n",
        "\n",
        "  cliprompt = ci.interrogate_fast(im)\n",
        "  if style_prompt:\n",
        "    cliprompt = cliprompt.split(\", \")\n",
        "    cliprompt.insert(1, style_prompt)\n",
        "    cliprompt = \", \".join(cliprompt)\n",
        "  print(f\"{xn:04d}: {cliprompt}\\n\")  \n",
        "  dialog.write(f\"{xn:04d}: {cliprompt},\\n\")\n",
        "  \n",
        "  image = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]\n",
        "  image.save(\"prev.png\")\n",
        "  os.system(\"python noiser.py -p prev.png -n \" +str(int(xn*2.8)))\n",
        "  image.save(f\"{dir_name}/{xn:04d}.png\")\n",
        "#  prog_noise(\"prev.png\", xn, 2.8)\n",
        "  #os.system(\"bash 1julien.sh st.png zi\") #my homemade zoom function\n",
        "  # and you will have to compile the video with ffmpeg or something\n",
        "dialog.close()\n",
        "\n",
        "# zip animation frames and put in Google Drive\n",
        "year_month_day = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "zip_name = f\"{year_month_day}_{dir_name}.zip\"\n",
        "\n",
        "!mv dialog.txt $dir_name/\n",
        "!zip -r $zip_name $dir_name/ \n",
        "!cp $zip_name $results_dir\n",
        "\n",
        "print(f\"Animation frames exported to {results_dir}/{zip_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " painting : photorealistic image rendered giza : Uxmal  desert, : jungle,  painting : rendered image  drawing : black and white photo : colorful stucco  egyptian men : elegant parrots on, : on surrounded by techno jungle,  dreadlocks : feathers skull:skully skull:white turnip apples:crystals green:green and red fractal:neon liquid paint splash psychedelic:asymmetric fractal kaleidoscop spiral:maze puzzle\n",
        " woman:flower headphones on:mechanical tendrils a close up : wide angle a close up of a person wearing headphones:wide angle view of a factory"
      ],
      "metadata": {
        "id": "h0jxlEw2EAi1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1QN-3NUFVtz"
      },
      "outputs": [],
      "source": [
        "#run this cell after starting cell above if you don't want to burn \n",
        "#google compute credits unnecessarily.\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "year_month_day = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "zip_name = f\"{year_month_day}_{dir_name}.zip\"\n",
        "!mv dialog.txt $dir_name/\n",
        "!zip -r $zip_name $dir_name/ \n",
        "!cp $zip_name $results_dir\n"
      ],
      "metadata": {
        "id": "INXZDUG5KepF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#working scrap section, sorry \n",
        "file2 = open(\"moto1.txt\")\n",
        "lines2 = file2.read().replace(\"\\n\", \" \")\n",
        "file2.close()\n",
        "moto=lines2.split(\" \")\n",
        "lenmo=len(moto)"
      ],
      "metadata": {
        "id": "iS3Na3rWdtBa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.5 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a226ec2bc5421555d34070094e17dd9cf5fa466c5c99c238543997899dd52977"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}