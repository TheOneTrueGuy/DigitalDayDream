{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheOneTrueGuy/DigitalDayDream/blob/main/Copy_of_FarStrike_Sonnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2gnooYgJmIt"
      },
      "outputs": [],
      "source": [
        "# What do these installs tell us about the code we are going to be writing?\n",
        "# How will the functions and operation depend on these dependencies?\n",
        "# What methods, variables, objects and function from these libraries will be used to achieve these ends?\n",
        "# watch closely for the imports and import from statements that call on these libraries.\n",
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install --upgrade accelerate #transformers\n",
        "!pip install omegaconf\n",
        "!apt-get install rsync # for better file transfer progress?\n",
        "!pip install noise\n",
        "!pip install anthropic # for Claude Sonnet\n",
        "# These libraries will be used to generate image-to-image diffusion model outputs specifically an image.\n",
        "# More specifically, diffusers is a library for training diffusion models, generating images\n",
        "# accelerate is a library for distributed inference, and transformers is a library for natural language processing.\n",
        "# and this package (notebook) as a whole is used to generate frames of an animation using diffusion models, huggingface pipelines and imagemagick convert command\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers\n",
        "#"
      ],
      "metadata": {
        "id": "hVKtC7mAat7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p43hYzDe0nXC"
      },
      "outputs": [],
      "source": [
        "#!pip install omegaconf #for use with deliberate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#!mkdir 8_1_2023\n",
        "!mkdir src\n",
        "\n",
        "#!cp /content/drive/MyDrive/stub_materials/p17.png  /content/st.png # cosmicconnection\n",
        "!cp /content/drive/MyDrive/stub_materials/bio10_12_23.txt /content/\n",
        "!cp /content/drive/MyDrive/stub_materials/building.txt /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBPvWwi2M29h"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt install imagemagick\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcljrDfeoyla"
      },
      "outputs": [],
      "source": [
        "#@title upload start image 512x512 will be quick and look good\n",
        "\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "name=uploaded.keys()\n",
        "name = list(name)[0]\n",
        "print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUODCru8OG0-"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.system(f\"convert {name} -resize 512x512! st.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "\n",
        "client = anthropic.Anthropic(\n",
        "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "    api_key=\"your anthropic key here\",\n",
        ")\n",
        "\n",
        "def generate_text(prompt):\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20240620\",\n",
        "        max_tokens=1024,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    print(message.content)\n",
        "    return message.content\n",
        "\n"
      ],
      "metadata": {
        "id": "c9GnSNY7tnDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "\n",
        "def load_and_encode_image(image_path, media_type):\n",
        "    with Image.open(image_path) as img:\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        img.save(img_byte_arr, format=media_type.split('/')[-1].upper())\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "        image_data = base64.b64encode(img_byte_arr).decode(\"utf-8\")\n",
        "    return {\n",
        "        \"data\": image_data,\n",
        "        \"media_type\": media_type\n",
        "    }\n",
        "\n",
        "def create_image_message(image_path, text_prompt):\n",
        "    # Determine media type based on file extension\n",
        "    media_type = f\"image/{image_path.split('.')[-1].lower()}\"\n",
        "    if media_type == \"image/jpg\":\n",
        "        media_type = \"image/jpeg\"\n",
        "\n",
        "    # Load and encode the image\n",
        "    image_info = load_and_encode_image(image_path, media_type)\n",
        "\n",
        "    # Set up the Anthropic client\n",
        "    client = anthropic.Anthropic()\n",
        "\n",
        "    # Create and return the message\n",
        "    return client.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20240620\",\n",
        "        max_tokens=1024,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image\",\n",
        "                        \"source\": {\n",
        "                            \"type\": \"base64\",\n",
        "                            \"media_type\": image_info['media_type'],\n",
        "                            \"data\": image_info['data'],\n",
        "                        },\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": text_prompt\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_path = \"st.png\"\n",
        "text_prompt = \"Describe this image.\"\n",
        "\n",
        "response = create_image_message(image_path, text_prompt)\n",
        "print(response)\n",
        "\n",
        "def image_to_message(img: Image.Image, text_prompt: str, media_type: str = None):\n",
        "    def encode_image(img: Image.Image, media_type: str):\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        img.save(img_byte_arr, format=media_type.split('/')[-1].upper())\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "        image_data = base64.b64encode(img_byte_arr).decode(\"utf-8\")\n",
        "        return {\n",
        "            \"data\": image_data,\n",
        "            \"media_type\": media_type\n",
        "        }\n",
        "\n",
        "    # Determine media type if not provided\n",
        "    if media_type is None:\n",
        "        if img.format == 'PNG':\n",
        "            media_type = 'image/png'\n",
        "        elif img.format in ['JPEG', 'JPG']:\n",
        "            media_type = 'image/jpeg'\n",
        "        else:\n",
        "            media_type = f'image/{img.format.lower()}'\n",
        "\n",
        "    # Encode the image\n",
        "    image_info = encode_image(img, media_type)\n",
        "\n",
        "    # Set up the Anthropic client\n",
        "    client = anthropic.Anthropic()\n",
        "\n",
        "    # Create and return the message\n",
        "    return client.messages.create(\n",
        "        model=\"claude-3-5-sonnet-20240620\",\n",
        "        max_tokens=1024,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image\",\n",
        "                        \"source\": {\n",
        "                            \"type\": \"base64\",\n",
        "                            \"media_type\": image_info['media_type'],\n",
        "                            \"data\": image_info['data'],\n",
        "                        },\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": text_prompt\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "id": "Iy0lTTIwzcIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4O2mYM6Kld4"
      },
      "outputs": [],
      "source": [
        "# run this first then make anim in next cell\n",
        "\n",
        "import torch\n",
        "\n",
        "from diffusers.utils import load_image\n",
        "from transformers import AutoTokenizer # for use with small sd\n",
        "\n",
        "import datetime as dt\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "from PIL import ImageFont, ImageDraw, Image, ImageOps, ImageChops, ImageFilter\n",
        "\n",
        "class FakeSafety():\n",
        "    def __call__(self, clip_input, images):\n",
        "        return (images, [False])\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "hf_auth=\"huggingface auth key here\"\n",
        "\n",
        "from diffusers import StableDiffusion3Img2ImgPipeline\n",
        "\n",
        "\n",
        "pipe = StableDiffusion3Img2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-3-medium-diffusers\",\n",
        "                                                torch_dtype=torch.float16, token=hf_auth,  text_encoder_3=None, tokenizer_3=None)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.safety_checker = FakeSafety()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "Ec7ofJFQQAom"
      },
      "outputs": [],
      "source": [
        "import string #cell number 11!\n",
        "# subject description, background, additional elements, effect, overall composition\n",
        "\n",
        "# how about trying this with a procedural method loop?\n",
        "\n",
        "zip_name = \"06_25_24_farstrike_sonnet.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "outdir = dt.datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "# if outdir exists add 4 random digits to it:\n",
        "if os.path.exists(outdir):\n",
        "    # Generate 4 random digits\n",
        "    random_digits = str(random.randint(1000, 9999))\n",
        "\n",
        "    # Create a new output directory with the random digits appended\n",
        "    new_outdir = outdir + random_digits\n",
        "\n",
        "    os.mkdir(new_outdir)\n",
        "    outdir=new_outdir\n",
        "    print(\"Created new output directory:\", new_outdir)\n",
        "else:\n",
        "    os.system(f\"mkdir {outdir}\")\n",
        "print(\"date time now:\" + outdir)\n",
        "\n",
        "os.system(f\"cp st.png {outdir}\")\n",
        "style=\"\" # can add style to prompt later\n",
        "\n",
        "xl=0.31\n",
        "xr=0\n",
        "gs=7.21\n",
        "gd=.1\n",
        "ns=0.65\n",
        "xz=0\n",
        "nx=0\n",
        "\n",
        "\n",
        "total=200\n",
        "xx = random.randint(2, 510)\n",
        "yy = random.randint(2, 510)\n",
        "tx = random.choice(string.ascii_lowercase + string.ascii_uppercase)\n",
        "\n",
        "negprompt=\"\"\n",
        "\n",
        "initial_value = 1  # Initial value of C2 use for exact-ish file count and timing\n",
        "\n",
        "\n",
        "\n",
        "image3= load_image(\"st.png\").convert(\"RGB\")\n",
        "for xn in range(0,total,1):#must equal xz\n",
        "\n",
        "\n",
        "  if xn%50==49: torch.cuda.empty_cache()\n",
        "\n",
        "  negstyle=\"\"\n",
        "  negprompt=\"\"\n",
        "  #negstyle=\"dumb, flat, ordinary, monochrome, boring, sad, insipid, ordinary, human face\" # , unhappy, worried, angry , weird face, scarlet, distorted face, weird nose\" # human, person, face, head, hands, man, woman, child, \" # dispirated, terrorized,  malformed hands, misshapen hands,\n",
        "  negprompt = negprompt + negstyle #prefix with style\n",
        "  print(prompt)\n",
        "\n",
        "  init_image = load_image(\"st.png\").convert(\"RGB\")\n",
        "\n",
        "  instruction=\"\"\"\n",
        "  This image is a frame in an animation. The animation subject is nanotechnology. Using the formula:\n",
        "   subject description, background, additional elements, effect, overall composition\n",
        "   you will suggest a brief image prompt that would change this image into the next frame in the animation. Reply only with:\n",
        "   subject description, background, additional elements, effect, overall composition\n",
        "  \"\"\"\n",
        "  prompt=image_to_message(init_image, instruction)\n",
        "\n",
        "  nsize=(512,512)\n",
        "  init_image=init_image.resize(nsize)\n",
        "  print(\"negative:\"+negprompt)\n",
        "\n",
        "  image2 = init_image\n",
        "  if xn>2:\n",
        "    image2=stacky.get_item(2)\n",
        "\n",
        "  image = pipe(\n",
        "               prompt,\n",
        "               num_inference_steps=28,\n",
        "               strength=0.5,\n",
        "               guidance_scale=gs, #11.721,\n",
        "               negative_prompt = negprompt,\n",
        "               image=init_image, # init_image,\n",
        "               ).images[0]\n",
        "  gs+=.006  #sr=sin_ratio(xn, 0.086)\n",
        "\n",
        "\n",
        "\n",
        "  stacky.push(image)\n",
        "  outname= \"st.png\"\n",
        "\n",
        "  out2=outdir+\"/st-\" + str(xz).zfill(4) + \".png\"\n",
        "  image.save(out2) # save animation frame\n",
        "  xz+=1\n",
        "  #out2=outdir+\"/st-\" + str(xz).zfill(4) + \".png\" # 3 lines added 2/14/24 to roll back remove/comment and change image.save above to imageb.save\n",
        "  #imageb.save(out2)\n",
        "  #xz+=1\n",
        "\n",
        "\n",
        "  image.save(outname)\n",
        "\n",
        "os.system(f\"cp 1julien3.sh {outdir}\")\n",
        "#os.system(f\"cp moto1g.txt {outdir}\")\n",
        "os.system(f\"zip -r {zip_name} {outdir}\")\n",
        "os.system(f\"cp {zip_name}  /content/drive/MyDrive/product\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxW7uiWg5sc3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aper71Lgrznq"
      },
      "outputs": [],
      "source": [
        "# Guy - don't you dare erase that!\n",
        "# split mode for top/bottom seperate motion\n",
        "def split_mode(img):\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA2piqTNzG6T"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvqYfOwUMKGO"
      },
      "outputs": [],
      "source": [
        "!zip -r 8_2_2023_farstrike2c.zip 20230802/\n",
        "!cp 8_2_2023_farstrike2c.zip  /content/drive/MyDrive/product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEHm3NtOSmwN"
      },
      "outputs": [],
      "source": [
        "os.system(f\"zip -r {zip_name} {outdir}\")\n",
        "os.system(f\"cp {zip_name}  /content/drive/MyDrive/product\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPT8t5cZnfjg"
      },
      "outputs": [],
      "source": [
        "print(zip_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4yyeR7YPa4p"
      },
      "outputs": [],
      "source": [
        "#run this cell after starting cell above if you don't want to burn\n",
        "#google compute credits unnecessarily.\n",
        "print(dt.datetime.now().strftime(\"%Y%M%d%h%m\"))\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGPZm4Q_3dVP"
      },
      "outputs": [],
      "source": [
        "xx = random.randint(2, 510)\n",
        "yy = random.randint(2, 510)\n",
        "tx = random.choice(string.ascii_lowercase + string.ascii_uppercase)\n",
        "init_image = load_image(\"st.png\").convert(\"RGB\")\n",
        "init_image=putText(tx, init_image, xx, yy, 84, 0, 0, 0)\n",
        "init_image.save('st.png')\n",
        "init_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dfIWkVqSMGc"
      },
      "outputs": [],
      "source": [
        "file = open(\"bio10_12_23.txt\") #be double sure to scrub your input\n",
        "line = file.read().replace(\"\\n\", \" \")\n",
        "line = line.replace(\"   \", \" \") # replace triple spaces\n",
        "line = line.replace(\"  \", \" \") # replace double spaces\n",
        "file.close()\n",
        "words=line.split(\" \")\n",
        "lenwo=len(words)\n",
        "print(lenwo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kyXISrVxlYU"
      },
      "outputs": [],
      "source": [
        "!pip install omegaconf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "215LaSpsdbWW"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
        "from diffusers.utils import load_image\n",
        "import datetime as dt\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class FakeSafety():\n",
        "    def __call__(self, clip_input, images):\n",
        "        return (images, False)\n",
        "\n",
        "#if pipe is None:\n",
        "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "  \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16\n",
        ")\n",
        "#pipe = pipe.to(\"cuda\")\n",
        "#pipe.safety_checker = FakeSafety()\n",
        "#excise all above after 8/3/2023 so that previous cell does all the pipe creation and handling\n",
        "\n",
        "#url = \"st-0027.png\"\n",
        "#\"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
        "# outdir should be a string of current date\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhK-63tOJfw_"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "device = \"cuda\"\n",
        "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
        "\n",
        "#response = requests.get(url)\n",
        "#init_image = Image.open(\"51P90MVCr8L._AC_UF894,1000_QL80_.jpg\").convert(\"RGB\")\n",
        "init_image = Image.open(\"fantasy_landscape.png\").convert(\"RGB\")\n",
        "\n",
        "#init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "#init_image = init_image.resize((768, 512))\n",
        "\n",
        "#prompt = \"Glossy movie poster, high quality, Kevin Sorbo in the live action Darkwing Duck remake with Keanu Reeves\"\n",
        "\n",
        "\n",
        "images = pipe(prompt=prompt, num_inference_steps=122, image=init_image, strength=0.95, guidance_scale=13.5).images\n",
        "images[0].save(\"fantasy_landscape2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhbpX6BRCqj6"
      },
      "outputs": [],
      "source": [
        "# pallette controls\n",
        "# convert input.png mask.png -fx 'u.r, u.g*1.5, u.b' output.png\n",
        "# convert input.png -separate -channel G -evaluate Multiply 1.5 +channel output.png\n",
        "# convert input.png mask.png -channel RGB -fx 'u.r + (u.g - u.r) * mask, u.g + (u.g - u.r) * mask, u.b + (u.g - u.r) * mask' output.png\n",
        "# convert input.png -channel RGB -fx 'clamp(u.r, 20, 70), clamp(u.g, 120, 255), clamp(u.b, 128, 191)' output.png\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDMVQ6BNsUoL"
      },
      "outputs": [],
      "source": [
        "!wget -O deliberatexp.safetensors  https://civitai.com/api/download/models/19724?type=Model&format=SafeTensor&size=full&fp=fp16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLhjVEk9jkky"
      },
      "outputs": [],
      "source": [
        "# convert img1.png img2.png -fx “(((255u)&(255(1-v)))|((255*(1-u))&(255*v)))/255” img3.png\n",
        "# convert image1.png image2.png -morphology HMT ‘3x3: 0,1,0 1,1,1 0,1,0’ result.png\n",
        "# convert image1.png image2.png -fx ‘u-v’ result.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7SwmNhZ5XHT"
      },
      "outputs": [],
      "source": [
        "#segmind/small-sd\n",
        "# distilled model\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipeline = DiffusionPipeline.from_pretrained(\"segmind/small-sd\", torch_dtype=torch.float16)\n",
        "prompt = \"Portrait of a pretty girl\"\n",
        "negative_prompt = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
        "image = pipeline(prompt, negative_prompt = negative_prompt).images[0]\n",
        "image.save(\"my_image.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_pE3PnOzLG_"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops\n",
        "\n",
        "# Open the two images you want to compare\n",
        "image1 = Image.open(\"image1.jpg\")\n",
        "image2 = Image.open(\"image2.jpg\")\n",
        "\n",
        "# Ensure that both images have the same size\n",
        "image2 = image2.resize(image1.size)\n",
        "\n",
        "# Calculate the absolute difference between the two images\n",
        "diff = ImageChops.difference(image1, image2)\n",
        "\n",
        "# You can use XOR instead of difference if you prefer\n",
        "# diff = ImageChops.logical_xor(image1, image2)\n",
        "\n",
        "# Convert the difference image to grayscale\n",
        "diff = diff.convert('L')\n",
        "\n",
        "# Threshold the difference image to create a mask\n",
        "threshold = 50  # You can adjust this threshold based on your needs\n",
        "mask = diff.point(lambda p: p > threshold and 255)\n",
        "\n",
        "# Save the mask image\n",
        "mask.save(\"difference_mask.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwhpTP7Y41Yi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops, ImageOps\n",
        "\n",
        "# Open the two images you want to compare\n",
        "image1 = Image.open(\"image1.jpg\")\n",
        "image2 = Image.open(\"image2.jpg\")\n",
        "\n",
        "# Ensure that both images have the same size\n",
        "image2 = image2.resize(image1.size)\n",
        "\n",
        "# Calculate the absolute difference between the two images\n",
        "diff = ImageChops.difference(image1, image2)\n",
        "\n",
        "# Convert the difference image to grayscale\n",
        "diff = diff.convert('L')\n",
        "\n",
        "# Threshold the difference image to create a mask\n",
        "threshold = 50  # You can adjust this threshold based on your needs\n",
        "mask = diff.point(lambda p: p > threshold and 255)\n",
        "\n",
        "# Invert the mask\n",
        "inverted_mask = ImageOps.invert(mask)\n",
        "\n",
        "# Invert the difference directly\n",
        "inverted_diff = ImageOps.invert(diff)\n",
        "\n",
        "# Blend the inverted difference back into the original image\n",
        "blend_factor = 0.1  # You can adjust this factor based on how much you want to reduce the difference\n",
        "result_image = Image.blend(image1, image2, blend_factor, inverted_diff)\n",
        "\n",
        "# Save the result image\n",
        "result_image.save(\"result_image.jpg\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNvk2vCmTr+Tf9kcgFFHbIQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}